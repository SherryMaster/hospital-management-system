# Logstash Configuration for Hospital Management System
# Comprehensive log processing and enrichment

input {
  # Django application logs
  beats {
    port => 5044
    type => "django"
  }
  
  # Nginx access logs
  file {
    path => "/var/log/nginx/access.log"
    start_position => "beginning"
    type => "nginx_access"
    codec => "json"
  }
  
  # Nginx error logs
  file {
    path => "/var/log/nginx/error.log"
    start_position => "beginning"
    type => "nginx_error"
  }
  
  # PostgreSQL logs
  file {
    path => "/var/log/postgresql/postgresql-*.log"
    start_position => "beginning"
    type => "postgresql"
  }
  
  # Redis logs
  file {
    path => "/var/log/redis/redis-server.log"
    start_position => "beginning"
    type => "redis"
  }
  
  # Celery logs
  file {
    path => "/var/log/celery/*.log"
    start_position => "beginning"
    type => "celery"
  }
  
  # System logs
  syslog {
    port => 514
    type => "syslog"
  }
  
  # Docker container logs
  docker {
    type => "docker"
  }
}

filter {
  # Common fields for all logs
  mutate {
    add_field => {
      "environment" => "${ENVIRONMENT:production}"
      "service" => "hospital-management"
      "version" => "${APP_VERSION:1.0.0}"
    }
  }
  
  # Parse Django logs
  if [type] == "django" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{DATA:logger}: %{GREEDYDATA:message}"
      }
    }
    
    # Parse Django request logs
    if [logger] == "django.request" {
      grok {
        match => {
          "message" => "%{WORD:method} %{URIPATH:path}(?:%{URIPARAM:params})? %{NUMBER:status_code:int} %{NUMBER:response_time:float}"
        }
      }
      
      # Categorize status codes
      if [status_code] >= 500 {
        mutate { add_field => { "log_category" => "error" } }
      } else if [status_code] >= 400 {
        mutate { add_field => { "log_category" => "warning" } }
      } else {
        mutate { add_field => { "log_category" => "info" } }
      }
    }
    
    # Parse Django security logs
    if [logger] == "django.security" {
      mutate { add_field => { "log_category" => "security" } }
      
      # Extract IP addresses for security analysis
      grok {
        match => {
          "message" => ".*from %{IP:client_ip}"
        }
      }
    }
    
    # Parse Django database logs
    if [logger] == "django.db.backends" {
      mutate { add_field => { "log_category" => "database" } }
      
      # Extract SQL query performance
      grok {
        match => {
          "message" => ".*\(%{NUMBER:query_time:float}s\) %{GREEDYDATA:sql_query}"
        }
      }
      
      # Flag slow queries
      if [query_time] and [query_time] > 1.0 {
        mutate { add_field => { "slow_query" => "true" } }
      }
    }
  }
  
  # Parse Nginx access logs
  if [type] == "nginx_access" {
    grok {
      match => {
        "message" => "%{NGINXACCESS}"
      }
    }
    
    # Parse user agent
    useragent {
      source => "agent"
      target => "user_agent"
    }
    
    # GeoIP lookup
    geoip {
      source => "clientip"
      target => "geoip"
    }
    
    # Categorize response codes
    if [response] >= 500 {
      mutate { add_field => { "log_category" => "error" } }
    } else if [response] >= 400 {
      mutate { add_field => { "log_category" => "warning" } }
    } else {
      mutate { add_field => { "log_category" => "info" } }
    }
    
    # Convert response time to float
    mutate {
      convert => { "request_time" => "float" }
    }
  }
  
  # Parse PostgreSQL logs
  if [type] == "postgresql" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{NUMBER:pid:int}\] %{WORD:level}: %{GREEDYDATA:message}"
      }
    }
    
    # Parse slow query logs
    if "duration:" in [message] {
      grok {
        match => {
          "message" => "duration: %{NUMBER:duration:float} ms.*statement: %{GREEDYDATA:sql_statement}"
        }
      }
      
      if [duration] and [duration] > 1000 {
        mutate { add_field => { "slow_query" => "true" } }
      }
    }
    
    # Parse connection logs
    if "connection" in [message] {
      mutate { add_field => { "log_category" => "connection" } }
    }
    
    # Parse error logs
    if [level] == "ERROR" or [level] == "FATAL" {
      mutate { add_field => { "log_category" => "error" } }
    }
  }
  
  # Parse Celery logs
  if [type] == "celery" {
    grok {
      match => {
        "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{LOGLEVEL:level}\/%{DATA:process}\] %{GREEDYDATA:message}"
      }
    }
    
    # Parse task execution logs
    if "Task" in [message] {
      grok {
        match => {
          "message" => "Task %{DATA:task_name}\[%{DATA:task_id}\] %{WORD:task_status}"
        }
      }
      
      if [task_status] == "FAILURE" {
        mutate { add_field => { "log_category" => "error" } }
      } else if [task_status] == "SUCCESS" {
        mutate { add_field => { "log_category" => "info" } }
      }
    }
  }
  
  # Parse timestamp
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }
  
  # Add hostname
  mutate {
    add_field => { "hostname" => "%{[host][name]}" }
  }
  
  # Remove sensitive information
  mutate {
    remove_field => [ "password", "token", "secret", "key" ]
  }
  
  # Anonymize patient data in logs
  if [message] =~ /patient_id/ {
    mutate {
      gsub => [ "message", "patient_id=\d+", "patient_id=***" ]
    }
  }
  
  # Add correlation ID for request tracing
  if [headers] and [headers][x-correlation-id] {
    mutate {
      add_field => { "correlation_id" => "%{[headers][x-correlation-id]}" }
    }
  }
  
  # Calculate response time buckets
  if [request_time] {
    if [request_time] < 0.1 {
      mutate { add_field => { "response_time_bucket" => "fast" } }
    } else if [request_time] < 1.0 {
      mutate { add_field => { "response_time_bucket" => "medium" } }
    } else {
      mutate { add_field => { "response_time_bucket" => "slow" } }
    }
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "hospital-logs-%{+YYYY.MM.dd}"
    template_name => "hospital-logs"
    template => "/etc/logstash/templates/hospital-logs.json"
    template_overwrite => true
  }
  
  # Send critical errors to alerting system
  if [level] == "ERROR" or [level] == "CRITICAL" or [log_category] == "error" {
    http {
      url => "http://alertmanager:9093/api/v1/alerts"
      http_method => "post"
      format => "json"
      mapping => {
        "alerts" => [
          {
            "labels" => {
              "alertname" => "LogError"
              "severity" => "warning"
              "service" => "%{type}"
              "environment" => "%{environment}"
            }
            "annotations" => {
              "summary" => "Error in %{type} logs"
              "description" => "%{message}"
            }
          }
        ]
      }
    }
  }
  
  # Send security events to SIEM
  if [log_category] == "security" {
    http {
      url => "http://siem-collector:8080/events"
      http_method => "post"
      format => "json"
    }
  }
  
  # Debug output (remove in production)
  if [environment] == "development" {
    stdout {
      codec => rubydebug
    }
  }
}
